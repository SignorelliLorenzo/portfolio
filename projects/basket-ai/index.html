<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/nav-black.png"/><link rel="preload" as="image" href="/nav-white.png"/><link rel="preload" as="image" href="/images/projects/ai-basket.png"/><link rel="preload" as="image" href="/markdown/basket-ai/88_labeled_top_corrected.png"/><link rel="preload" as="image" href="/markdown/basket-ai/teams.gif"/><link rel="preload" as="image" href="/markdown/basket-ai/grafico.png"/><link rel="preload" as="image" href="/markdown/basket-ai/pose.webp"/><link rel="stylesheet" href="/portfolio/_next/static/css/33258f34a30a0add.css" data-precedence="next"/><link rel="stylesheet" href="/portfolio/_next/static/css/a81e9d642ce3e415.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/portfolio/_next/static/chunks/webpack-5a2a2b6d377af9c4.js"/><script src="/portfolio/_next/static/chunks/4bd1b696-16d61eec428fe094.js" async=""></script><script src="/portfolio/_next/static/chunks/684-1a924adb22a2205d.js" async=""></script><script src="/portfolio/_next/static/chunks/main-app-847009363d598137.js" async=""></script><script src="/portfolio/_next/static/chunks/359-fe7aaaf0b8b56caa.js" async=""></script><script src="/portfolio/_next/static/chunks/780-2f4b189908922a3e.js" async=""></script><script src="/portfolio/_next/static/chunks/app/projects/%5Bid%5D/page-f38748e9e9ab6f59.js" async=""></script><title>Lorenzo Signorelli</title><meta name="description" content="My porfolio website"/><style>
html {
  font-family: 'GeistSans', 'GeistSans Fallback';
  --font-sans: __variable_81ea09;
  --font-mono: __variable_a1547a;
}
        </style><script src="/portfolio/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="overflow-y-auto no-scrollbar"><div class="min-h-screen bg-background"><nav class="fixed top-0 left-0 right-0 z-50 transition-all duration-300 bg-transparent"><div class="max-w-6xl mx-auto px-6 "><div class="flex justify-between items-center"><div class="text-xl font-bold"><img src="/nav-black.png" alt="Light Icon" class="h-15 w-15 dark:hidden"/><img src="/nav-white.png" alt="Dark Icon" class="h-15 w-15 hidden dark:inline"/></div><div class="flex items-center space-x-6 py-4 "><a class="font-medium transition-all duration-300 text-black dark:text-white hover:text-blue-500 dark:hover:text-purple-400 hover:drop-shadow-[0_0_10px_rgba(147,51,234,0.8)] dark:hover:drop-shadow-[0_0_10px_rgba(147,51,234,0.8)]" href="/portfolio/#about">About Me</a><a class="font-medium transition-all duration-300 text-black dark:text-white hover:text-blue-500 dark:hover:text-purple-400 hover:drop-shadow-[0_0_10px_rgba(147,51,234,0.8)] dark:hover:drop-shadow-[0_0_10px_rgba(147,51,234,0.8)]" href="/portfolio/#projects">Projects</a><button class="p-2 rounded-lg bg-card hover:bg-accent/20 transition-all duration-300 hover:drop-shadow-[0_0_12px_rgba(147,51,234,0.4)] border border-border" aria-label="Toggle theme"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-moon h-5 w-5 text-secondary"><path d="M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z"></path></svg></button></div></div></div></nav><main class="max-w-6xl mx-auto my-10 px-1 sm:px-6 py-16 space-y-16"><div class="grid md:grid-cols-2 gap-10 items-center mt-6" style="opacity:0;transform:translateY(40px)"><img src="/images/projects/ai-basket.png" alt="Basket AI" class="rounded-2xl shadow-lg dark:shadow-black/50" style="opacity:0;transform:scale(0.9)"/><div class="space-y-5"><h1 class="text-5xl font-extrabold text-foreground leading-tight">Basket AI</h1><p class="text-lg text-muted-foreground">Exploring computer vision techniques to generate live basketball box scores from video.</p><div class="flex space-x-4"><button data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground shadow-xs hover:bg-primary/90 h-9 px-4 py-2 has-[&gt;svg]:px-3 opacity-50 cursor-not-allowed" disabled="">See Code on GitHub</button></div></div></div><div style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-semibold mb-4">Key Features</h2><div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-5 gap-4"><div class="p-4 rounded-2xl shadow-md bg-card text-card-foreground border dark:shadow-[0_4px_6px_rgba(139,92,246,0.5)]" style="opacity:0;transform:translateY(10px)">Player detection with YOLO</div><div class="p-4 rounded-2xl shadow-md bg-card text-card-foreground border dark:shadow-[0_4px_6px_rgba(139,92,246,0.5)]" style="opacity:0;transform:translateY(10px)">Tracking using ByteTrack</div><div class="p-4 rounded-2xl shadow-md bg-card text-card-foreground border dark:shadow-[0_4px_6px_rgba(139,92,246,0.5)]" style="opacity:0;transform:translateY(10px)">Squad clustering with K-Means</div><div class="p-4 rounded-2xl shadow-md bg-card text-card-foreground border dark:shadow-[0_4px_6px_rgba(139,92,246,0.5)]" style="opacity:0;transform:translateY(10px)">Segmentation with SAM</div><div class="p-4 rounded-2xl shadow-md bg-card text-card-foreground border dark:shadow-[0_4px_6px_rgba(139,92,246,0.5)]" style="opacity:0;transform:translateY(10px)">Number recognition with Parseq</div></div></div><div class="prose max-w-none dark:prose-invert" style="opacity:0;transform:translateY(20px)"><section class="min-h-screen flex items-start justify-center px-1 sm:px-6 py-20"><div class="max-w-4xl w-full prose dark:prose-invert space-y-6 text-foreground"><h1 class="text-4xl md:text-5xl font-bold text-foreground mt-8 mb-4">Basket-AI: Building a Low-Cost Basketball Tracking System with AI</h1>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><em>Author: Lorenzo Signorelli</em></p>
<hr/>
<h2 class="text-3xl md:text-4xl font-semibold text-foreground mt-6 mb-3 border-b border-muted/30 pb-1">Introduction &amp; Project Vision</h2>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4">Professional basketball leagues like the NBA utilize advanced tracking systems that combine multiple high-resolution cameras, proprietary sensors, and complex data pipelines. These systems provide unparalleled insights into player movement, ball physics, and team tactics. However, with costs reaching hundreds of thousands of euros, this technology remains inaccessible for most national federations and smaller clubs.</p>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4">In Italy, game analysis is still predominantly manual. Coaches and analysts spend countless hours reviewing game footage to extract basic statistics and tactical patterns—a time-consuming and subjective process.</p>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><strong>Basket-AI</strong> emerged as a research initiative with a clear, ambitious goal: to develop an affordable, AI-powered alternative that automates the most repetitive aspects of game analysis. The system is designed not to replace coaches, but to empower them with automated data extraction, reducing their manual workload and providing objective insights.</p>
<hr/>
<h2 class="text-3xl md:text-4xl font-semibold text-foreground mt-6 mb-3 border-b border-muted/30 pb-1">System Architecture &amp; Technical Deep Dive</h2>
<h3 class="text-xl md:text-2xl font-medium text-foreground/80 mt-5 mb-2 tracking-wide">1. Player Detection</h3>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><strong>Objective:</strong> Reliably identify and locate all players on the court in every frame.</p>
<ul class="list-disc list-inside space-y-2 pl-4">
<li class="text-muted-foreground"><strong>Model:</strong> YOLOv11 (nano variant for speed/accuracy balance).</li>
<li class="text-muted-foreground"><strong>Training Data:</strong> Custom dataset of ~1,500 manually annotated images.</li>
<li class="text-muted-foreground"><strong>Camera Setup:</strong> Two static cameras mounted overhead on opposite sides of the court. This top-down perspective was chosen to minimize player occlusions compared to a ground-level view.</li>
<li class="text-muted-foreground"><strong>Result:</strong> The fine-tuned model achieved stable and precise player bounding box detection across various lighting conditions and game phases.</li>
</ul>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><img class="rounded-xl shadow-lg mx-auto my-6" src="/markdown/basket-ai/88_labeled_top_corrected.png" alt="Player_Tracking"/></p>
<hr/>
<h3 class="text-xl md:text-2xl font-medium text-foreground/80 mt-5 mb-2 tracking-wide">2. Ball Detection</h3>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><strong>Objective:</strong> Track the small, fast-moving basketball with high consistency.</p>
<ul class="list-disc list-inside space-y-2 pl-4">
<li class="text-muted-foreground"><strong>Challenge:</strong> The ball is a small object that moves at high velocity and is often occluded by players&#x27; hands or bodies.</li>
<li class="text-muted-foreground"><strong>Model:</strong> A separate, specialized YOLO model trained specifically on ball instances.</li>
<li class="text-muted-foreground"><strong>Training Data:</strong> Dataset enriched with images focusing on ball during passes, shots, and dribbles.</li>
<li class="text-muted-foreground"><strong>Result:</strong> The model successfully localized the ball in most frames, though occasional drops occurred during heavy occlusions or motion blur.</li>
</ul>
<hr/>
<h3 class="text-xl md:text-2xl font-medium text-foreground/80 mt-5 mb-2 tracking-wide">3. Team Identification (Player Segmentation &amp; Clustering)</h3>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><strong>Objective:</strong> Assign each detected player to their correct team based on jersey color.</p>
<ul class="list-disc list-inside space-y-2 pl-4">
<li class="text-muted-foreground"><strong>Initial Challenge:</strong> Simple color clustering (K-Means) on the raw player crop was highly sensitive to background colors from the court, stands, and shadows, leading to misclassifications.</li>
<li class="text-muted-foreground"><strong>Solution: A Two-Step Pipeline</strong>
<ol class="list-decimal list-inside space-y-2 pl-4">
<li class="text-muted-foreground"><strong>Precise Segmentation:</strong> Used the Segment Anything Model (SAM2), prompted by the YOLO bounding boxes, to generate precise pixel-level masks for each player. This effectively removed the background, leaving only the player and their jersey.</li>
<li class="text-muted-foreground"><strong>Robust Clustering:</strong> Applied K-Means clustering on the dominant color channels (e.g., in HSV color space) extracted from the segmented player images. This was combined with color histogram comparisons to improve separation.</li>
</ol>
</li>
<li class="text-muted-foreground"><strong>Enhancement:</strong> When the jersey colors for both teams were known beforehand (e.g., &quot;white&quot; vs. &quot;blue&quot;), the clustering process was guided by this information, significantly boosting accuracy and reliability.</li>
</ul>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><img class="rounded-xl shadow-lg mx-auto my-6" src="/markdown/basket-ai/teams.gif" alt="Team_tracking"/></p>
<hr/>
<h3 class="text-xl md:text-2xl font-medium text-foreground/80 mt-5 mb-2 tracking-wide">4. Jersey Number Recognition</h3>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><strong>Objective:</strong> Identify the jersey number of a player to assign a unique identity, a critical step before tracking.</p>
<ul class="list-disc list-inside space-y-2 pl-4">
<li class="text-muted-foreground"><strong>Core Problem:</strong> Off-the-shelf OCR models like PARSeq perform poorly on jersey numbers without precise localization due to unusual fonts, folds in the fabric, and motion blur.</li>
<li class="text-muted-foreground"><strong>Developed Pipeline:</strong>
<ol class="list-decimal list-inside space-y-2 pl-4">
<li class="text-muted-foreground"><strong>Localization:</strong> Trained a custom YOLO model to detect the specific region of the jersey where the number is located (e.g., upper back). This acted as a high-quality region proposer.</li>
<li class="text-muted-foreground"><strong>Recognition:</strong> Cropped the proposed region and passed it to the PARSeq model for actual digit recognition.</li>
</ol>
</li>
<li class="text-muted-foreground"><strong>Performance:</strong> Achieved <strong>79% accuracy</strong> on a challenging test set of 131 images where the number was at least partially visible.</li>
</ul>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><img class="rounded-xl shadow-lg mx-auto my-6" src="/markdown/basket-ai/grafico.png" alt="Team_tracking"/></p>
<hr/>
<h3 class="text-xl md:text-2xl font-medium text-foreground/80 mt-5 mb-2 tracking-wide">5. Multi-Object Tracking (MOT) - The Core Challenge</h3>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><strong>Objective:</strong> Maintain a consistent identity (ID) for each player and the ball across the entire video sequence.</p>
<ul class="list-disc list-inside space-y-2 pl-4">
<li class="text-muted-foreground"><strong>Model Tested:</strong> ByteTrack, which combines motion prediction (Kalman Filter) with appearance similarity matching to link detections across frames.</li>
<li class="text-muted-foreground"><strong>Primary Obstacles:</strong>
<ul class="list-disc list-inside space-y-2 pl-4">
<li class="text-muted-foreground"><strong>Visual Similarity:</strong> From an overhead view, players on the same team look nearly identical, offering little for appearance-based models to distinguish.</li>
<li class="text-muted-foreground"><strong>Occlusions &amp; Motion:</strong> Frequent collisions and rapid direction changes often broke the Kalman Filter’s motion assumptions.</li>
</ul>
</li>
<li class="text-muted-foreground"><strong>Result:</strong> The tracker experienced frequent <strong>ID switches</strong> (a player’s identity changing mid-play) and track fragmentation. This made the outputs unreliable for downstream analysis. With stronger ReID models and a camera angle that captures more distinctive body features, tracking performance could improve.</li>
<li class="text-muted-foreground"><strong>Current Outlook:</strong> Our first implementation was unstable, and due to the <strong>lack of sufficient resources (hardware, camera setup, and model fine-tuning), the client decided to discontinue the project</strong>. While newer trackers integrated into frameworks like Ultralytics could improve results, achieving <strong>unsupervised, robust MOT</strong> in a visually homogeneous sports environment remains an open challenge.</li>
</ul>
<hr/>
<blockquote class="border-l-4 border-secondary pl-4 italic text-muted-foreground my-4">
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><strong>Note:</strong> Since the client decided to stop MOT development due to missing resources, follow-up tasks such as pose estimation could not be initiated. MOT was a crucial part of the project and needed to be sorted out first.</p>
</blockquote>
<hr/>
<h3 class="text-xl md:text-2xl font-medium text-foreground/80 mt-5 mb-2 tracking-wide">6. Pose Estimation <em>(Not Initiated)</em></h3>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4"><strong>Objective:</strong> Estimate the skeletal pose of each player to analyze movements such as jumps, defensive stances, and shooting form.</p>
<ul class="list-disc list-inside space-y-2 pl-4">
<li class="text-muted-foreground"><strong>Status:</strong> This task was never started. Since the MOT system itself required significantly more resources — and was ultimately discontinued by the client — pose estimation was postponed until a reliable tracking pipeline could be established.</li>
<li class="text-muted-foreground"><strong>Potential Solution:</strong> Once MOT becomes feasible, lightweight models like YOLO-Pose could be fine-tuned for this task.</li>
</ul>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4" align="center">  
  <img class="rounded-xl shadow-lg mx-auto my-6" src="/markdown/basket-ai/pose.webp" alt="Pose Estimation" width="500" style="margin-bottom:5px"/>  
  <em>Source: <a class="text-sm md:text-base text-primary font-medium no-underline hover:underline hover:text-primary/80 transition-colors" target="_blank" rel="noopener noreferrer" href="https://posetrack.net/">PoseTrack</a></em>  
</p>  
<hr/>
<h2 class="text-3xl md:text-4xl font-semibold text-foreground mt-6 mb-3 border-b border-muted/30 pb-1">Results &amp; Performance Overview</h2>
<table class="w-full text-xs sm:text-sm border-collapse my-6"><thead class="text-foreground font-semibold"><tr class="even:bg-muted/10"><th class="p-3 text-left font-semibold border-b border-black dark:border-white">Task</th><th class="p-3 text-left font-semibold border-b border-black dark:border-white">Methodology</th><th class="p-3 text-left font-semibold border-b border-black dark:border-white">Outcome &amp; Notes</th></tr></thead><tbody><tr class="even:bg-muted/10"><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">Player Detection</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">Fine-tuned YOLOv11</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground"><strong>Stable.</strong> High recall and precision in overhead view.</td></tr><tr class="even:bg-muted/10"><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">Ball Detection</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">Specialized YOLO model</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground"><strong>Good.</strong> Reliable but can drop during extreme occlusion or blur.</td></tr><tr class="even:bg-muted/10"><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">Team Identification</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">SAM2 + K-Means + Color Histograms</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground"><strong>Robust.</strong> Highly dependent on successful background removal.</td></tr><tr class="even:bg-muted/10"><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">Number Recognition</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">YOLO (Localization) + PARSeq (OCR)</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground"><strong>79% Accuracy.</strong> Effective on visible numbers.</td></tr><tr class="even:bg-muted/10"><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">Pose Estimation</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">OpenPose / YOLO-NAS Pose</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground"><strong>Not Implemented.</strong> Project suspended.</td></tr><tr class="even:bg-muted/10"><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">Multi-Object Tracking</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground">ByteTrack</td><td class="p-3 align-top border-b border-black dark:border-white text-muted-foreground"><strong>Unstable.</strong> ID switches are frequent due to visual similarity from top-down. Fixes expensive.</td></tr></tbody></table>
<hr/>
<h2 class="text-3xl md:text-4xl font-semibold text-foreground mt-6 mb-3 border-b border-muted/30 pb-1">Conclusion &amp; Future Perspectives</h2>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4">The Basket-AI project successfully demonstrated that core components of a professional basketball tracking system can be replicated using modern computer vision and AI at a fraction of the cost. We built a robust pipeline for <strong>player detection, ball localization, team assignment, and jersey number recognition.</strong></p>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4">The primary hurdle, and the reason for the project&#x27;s pause, was <strong>Multi-Object Tracking (MOT)</strong>. From this challenge, a broader insight emerged: the future of practical computer vision lies in solving robust, long-term MOT. Reliable MOT is the key that unlocks the transition from simple frame-by-frame detection to true <strong>temporal understanding</strong>:</p>
<ul class="list-disc list-inside space-y-2 pl-4">
<li class="text-muted-foreground"><strong>In Sports:</strong> Analyzing full plays, calculating player travel distance, and measuring team formation dynamics.</li>
<li class="text-muted-foreground"><strong>In Autonomous Driving:</strong> Tracking vehicles and pedestrians across time to predict trajectories.</li>
<li class="text-muted-foreground"><strong>In Security &amp; Retail:</strong> Monitoring customer flow and behavior in a store over a complete session.</li>
</ul>
<p class="text-base md:text-lg leading-relaxed text-muted-foreground mb-4">Solving MOT would democratize these advanced analytics, making them accessible without the need for the vast resources of large corporations or elite leagues. While Basket-AI is currently paused, it serves as a foundational proof-of-concept and a clear map toward the future of affordable, AI-powered sports analytics.</p></div></section></div></main><footer class="w-full border-t border-black/10 dark:border-white/10 bg-white/95 dark:bg-black/95 backdrop-blur-sm shadow-inner transition-all duration-300"><div class="max-w-6xl mx-auto px-6 py-6"><div class="flex flex-col-reverse md:flex-row justify-between items-center gap-6"><div class="text-sm text-black dark:text-gray-300 text-center md:text-left">© <!-- -->2025<!-- --> Portfolio. All rights reserved.</div><div class="flex flex-col md:flex-row gap-6 text-sm text-center md:text-left"><div class="flex items-center justify-center md:justify-start gap-2 text-black dark:text-white"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-phone w-4 h-4"><path d="M22 16.92v3a2 2 0 0 1-2.18 2 19.79 19.79 0 0 1-8.63-3.07 19.5 19.5 0 0 1-6-6 19.79 19.79 0 0 1-3.07-8.67A2 2 0 0 1 4.11 2h3a2 2 0 0 1 2 1.72 12.84 12.84 0 0 0 .7 2.81 2 2 0 0 1-.45 2.11L8.09 9.91a16 16 0 0 0 6 6l1.27-1.27a2 2 0 0 1 2.11-.45 12.84 12.84 0 0 0 2.81.7A2 2 0 0 1 22 16.92z"></path></svg><span>+39 335 586 0184</span></div><div class="flex items-center justify-center md:justify-start gap-2 text-black dark:text-white"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail w-4 h-4"><rect width="20" height="16" x="2" y="4" rx="2"></rect><path d="m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"></path></svg><a class="transition-all duration-300 hover:text-blue-500 dark:hover:text-purple-400 hover:drop-shadow-[0_0_10px_rgba(147,51,234,0.8)] dark:hover:drop-shadow-[0_0_10px_rgba(147,51,234,0.8)]" href="mailto:signorelli.lorenzo.business@gmail.com">signorelli.lorenzo.business@gmail.com</a></div><div class="flex items-center justify-center md:justify-start gap-2 text-black dark:text-white"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-map-pin w-4 h-4"><path d="M20 10c0 4.993-5.539 10.193-7.399 11.799a1 1 0 0 1-1.202 0C9.539 20.193 4 14.993 4 10a8 8 0 0 1 16 0"></path><circle cx="12" cy="10" r="3"></circle></svg><span>Bergamo, Italy</span></div></div></div></div></footer></div><script src="/portfolio/_next/static/chunks/webpack-5a2a2b6d377af9c4.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n5:I[9665,[],\"OutletBoundary\"]\n8:I[9665,[],\"ViewportBoundary\"]\na:I[9665,[],\"MetadataBoundary\"]\nc:I[6614,[],\"\"]\n:HL[\"/portfolio/_next/static/css/33258f34a30a0add.css\",\"style\"]\n:HL[\"/portfolio/_next/static/css/a81e9d642ce3e415.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"drtaHnksUpatlvlk5uIQK\",\"p\":\"/portfolio\",\"c\":[\"\",\"projects\",\"basket-ai\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"projects\",{\"children\":[[\"id\",\"basket-ai\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/portfolio/_next/static/css/33258f34a30a0add.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/portfolio/_next/static/css/a81e9d642ce3e415.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"style\",null,{\"children\":\"\\nhtml {\\n  font-family: 'GeistSans', 'GeistSans Fallback';\\n  --font-sans: __variable_81ea09;\\n  --font-mono: __variable_a1547a;\\n}\\n        \"}]}],[\"$\",\"body\",null,{\"className\":\"overflow-y-auto no-scrollbar\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}]]}],{\"children\":[\"projects\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"id\",\"basket-ai\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",\"$undefined\",null,[\"$\",\"$L5\",null,{\"children\":[\"$L6\",\"$L7\",null]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"EntlnOCYsic8gbGE_Erw0\",{\"children\":[[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],null]}],[\"$\",\"$La\",null,{\"children\":\"$Lb\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$c\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"d:I[8989,[\"359\",\"static/chunks/359-fe7aaaf0b8b56caa.js\",\"780\",\"static/chunks/780-2f4b189908922a3e.js\",\"801\",\"static/chunks/app/projects/%5Bid%5D/page-f38748e9e9ab6f59.js\"],\"Navbar\"]\ne:I[5677,[\"359\",\"static/chunks/359-fe7aaaf0b8b56caa.js\",\"780\",\"static/chunks/780-2f4b189908922a3e.js\",\"801\",\"static/chunks/app/projects/%5Bid%5D/page-f38748e9e9ab6f59.js\"],\"default\"]\nf:I[4482,[\"359\",\"static/chunks/359-fe7aaaf0b8b56caa.js\",\"780\",\"static/chunks/780-2f4b189908922a3e.js\",\"801\",\"static/chunks/app/projects/%5Bid%5D/page-f38748e9e9ab6f59.js\"],\"default\"]\n10:I[3843,[\"359\",\"static/chunks/359-fe7aaaf0b8b56caa.js\",\"780\",\"static/chunks/780-2f4b189908922a3e.js\",\"801\",\"static/chunks/app/projects/%5Bid%5D/page-f38748e9e9ab6f59.js\"],\"default\"]\n11:I[8332,[\"359\",\"static/chunks/359-fe7aaaf0b8b56caa.js\",\"780\",\"static/chunks/780-2f4b189908922a3e.js\",\"801\",\"static/chunks/app/projects/%5Bid%5D/page-f38748e9e9ab6f59.js\"],\"default\"]\n13:I[7746,[\"359\",\"static/chunks/359-fe7aaaf0b8b56caa.js\",\"780\",\"static/chunks/780-2f4b189908922a3e.js\",\"801\",\"static/chunks/app/projects/%5Bid%5D/page-f38748e9e9ab6f59.js\"],\"Footer\"]\n12:T2594,"])</script><script>self.__next_f.push([1,"# Basket-AI: Building a Low-Cost Basketball Tracking System with AI\r\n\r\n*Author: Lorenzo Signorelli*\r\n\r\n---\r\n\r\n## Introduction \u0026 Project Vision\r\n\r\nProfessional basketball leagues like the NBA utilize advanced tracking systems that combine multiple high-resolution cameras, proprietary sensors, and complex data pipelines. These systems provide unparalleled insights into player movement, ball physics, and team tactics. However, with costs reaching hundreds of thousands of euros, this technology remains inaccessible for most national federations and smaller clubs.\r\n\r\nIn Italy, game analysis is still predominantly manual. Coaches and analysts spend countless hours reviewing game footage to extract basic statistics and tactical patterns—a time-consuming and subjective process.\r\n\r\n**Basket-AI** emerged as a research initiative with a clear, ambitious goal: to develop an affordable, AI-powered alternative that automates the most repetitive aspects of game analysis. The system is designed not to replace coaches, but to empower them with automated data extraction, reducing their manual workload and providing objective insights.\r\n\r\n---\r\n\r\n## System Architecture \u0026 Technical Deep Dive\r\n\r\n### 1. Player Detection\r\n**Objective:** Reliably identify and locate all players on the court in every frame.  \r\n*   **Model:** YOLOv11 (nano variant for speed/accuracy balance).  \r\n*   **Training Data:** Custom dataset of ~1,500 manually annotated images.  \r\n*   **Camera Setup:** Two static cameras mounted overhead on opposite sides of the court. This top-down perspective was chosen to minimize player occlusions compared to a ground-level view.  \r\n*   **Result:** The fine-tuned model achieved stable and precise player bounding box detection across various lighting conditions and game phases.  \r\n\r\n![Player_Tracking](/markdown/basket-ai/88_labeled_top_corrected.png)\r\n\r\n---\r\n\r\n### 2. Ball Detection\r\n**Objective:** Track the small, fast-moving basketball with high consistency.  \r\n*   **Challenge:** The ball is a small object that moves at high velocity and is often occluded by players' hands or bodies.  \r\n*   **Model:** A separate, specialized YOLO model trained specifically on ball instances.  \r\n*   **Training Data:** Dataset enriched with images focusing on ball during passes, shots, and dribbles.  \r\n*   **Result:** The model successfully localized the ball in most frames, though occasional drops occurred during heavy occlusions or motion blur.  \r\n\r\n---\r\n\r\n### 3. Team Identification (Player Segmentation \u0026 Clustering)\r\n**Objective:** Assign each detected player to their correct team based on jersey color.  \r\n*   **Initial Challenge:** Simple color clustering (K-Means) on the raw player crop was highly sensitive to background colors from the court, stands, and shadows, leading to misclassifications.  \r\n*   **Solution: A Two-Step Pipeline**\r\n    1.  **Precise Segmentation:** Used the Segment Anything Model (SAM2), prompted by the YOLO bounding boxes, to generate precise pixel-level masks for each player. This effectively removed the background, leaving only the player and their jersey.  \r\n    2.  **Robust Clustering:** Applied K-Means clustering on the dominant color channels (e.g., in HSV color space) extracted from the segmented player images. This was combined with color histogram comparisons to improve separation.  \r\n*   **Enhancement:** When the jersey colors for both teams were known beforehand (e.g., \"white\" vs. \"blue\"), the clustering process was guided by this information, significantly boosting accuracy and reliability.  \r\n\r\n![Team_tracking](/markdown/basket-ai/teams.gif)\r\n\r\n---\r\n\r\n### 4. Jersey Number Recognition\r\n**Objective:** Identify the jersey number of a player to assign a unique identity, a critical step before tracking.  \r\n*   **Core Problem:** Off-the-shelf OCR models like PARSeq perform poorly on jersey numbers without precise localization due to unusual fonts, folds in the fabric, and motion blur.  \r\n*   **Developed Pipeline:**\r\n    1.  **Localization:** Trained a custom YOLO model to detect the specific region of the jersey where the number is located (e.g., upper back). This acted as a high-quality region proposer.  \r\n    2.  **Recognition:** Cropped the proposed region and passed it to the PARSeq model for actual digit recognition.  \r\n*   **Performance:** Achieved **79% accuracy** on a challenging test set of 131 images where the number was at least partially visible.  \r\n\r\n![Team_tracking](/markdown/basket-ai/grafico.png)\r\n\r\n---\r\n\r\n### 5. Multi-Object Tracking (MOT) - The Core Challenge  \r\n**Objective:** Maintain a consistent identity (ID) for each player and the ball across the entire video sequence.  \r\n\r\n*   **Model Tested:** ByteTrack, which combines motion prediction (Kalman Filter) with appearance similarity matching to link detections across frames.  \r\n*   **Primary Obstacles:**  \r\n    *   **Visual Similarity:** From an overhead view, players on the same team look nearly identical, offering little for appearance-based models to distinguish.  \r\n    *   **Occlusions \u0026 Motion:** Frequent collisions and rapid direction changes often broke the Kalman Filter’s motion assumptions.  \r\n*   **Result:** The tracker experienced frequent **ID switches** (a player’s identity changing mid-play) and track fragmentation. This made the outputs unreliable for downstream analysis. With stronger ReID models and a camera angle that captures more distinctive body features, tracking performance could improve.  \r\n*   **Current Outlook:** Our first implementation was unstable, and due to the **lack of sufficient resources (hardware, camera setup, and model fine-tuning), the client decided to discontinue the project**. While newer trackers integrated into frameworks like Ultralytics could improve results, achieving **unsupervised, robust MOT** in a visually homogeneous sports environment remains an open challenge.  \r\n\r\n---\r\n\r\n\u003e **Note:** Since the client decided to stop MOT development due to missing resources, follow-up tasks such as pose estimation could not be initiated. MOT was a crucial part of the project and needed to be sorted out first.  \r\n\r\n---\r\n\r\n### 6. Pose Estimation *(Not Initiated)*  \r\n**Objective:** Estimate the skeletal pose of each player to analyze movements such as jumps, defensive stances, and shooting form.  \r\n\r\n*   **Status:** This task was never started. Since the MOT system itself required significantly more resources — and was ultimately discontinued by the client — pose estimation was postponed until a reliable tracking pipeline could be established.  \r\n*   **Potential Solution:** Once MOT becomes feasible, lightweight models like YOLO-Pose could be fine-tuned for this task.  \r\n\r\n\u003cp align=\"center\"\u003e  \r\n  \u003cimg src=\"/markdown/basket-ai/pose.webp\" alt=\"Pose Estimation\" width=\"500\" style=\"margin-bottom:5px\"/\u003e  \r\n  \u003cem\u003eSource: \u003ca href=\"https://posetrack.net/\"\u003ePoseTrack\u003c/a\u003e\u003c/em\u003e  \r\n\u003c/p\u003e  \r\n\r\n---\r\n\r\n## Results \u0026 Performance Overview\r\n\r\n\u003ctable\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eTask\u003c/th\u003e\r\n      \u003cth\u003eMethodology\u003c/th\u003e\r\n      \u003cth\u003eOutcome \u0026 Notes\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003ctd\u003ePlayer Detection\u003c/td\u003e\r\n      \u003ctd\u003eFine-tuned YOLOv11\u003c/td\u003e\r\n      \u003ctd\u003e\u003cstrong\u003eStable.\u003c/strong\u003e High recall and precision in overhead view.\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003ctd\u003eBall Detection\u003c/td\u003e\r\n      \u003ctd\u003eSpecialized YOLO model\u003c/td\u003e\r\n      \u003ctd\u003e\u003cstrong\u003eGood.\u003c/strong\u003e Reliable but can drop during extreme occlusion or blur.\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003ctd\u003eTeam Identification\u003c/td\u003e\r\n      \u003ctd\u003eSAM2 + K-Means + Color Histograms\u003c/td\u003e\r\n      \u003ctd\u003e\u003cstrong\u003eRobust.\u003c/strong\u003e Highly dependent on successful background removal.\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003ctd\u003eNumber Recognition\u003c/td\u003e\r\n      \u003ctd\u003eYOLO (Localization) + PARSeq (OCR)\u003c/td\u003e\r\n      \u003ctd\u003e\u003cstrong\u003e79% Accuracy.\u003c/strong\u003e Effective on visible numbers.\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003ctd\u003ePose Estimation\u003c/td\u003e\r\n      \u003ctd\u003eOpenPose / YOLO-NAS Pose\u003c/td\u003e\r\n      \u003ctd\u003e\u003cstrong\u003eNot Implemented.\u003c/strong\u003e Project suspended.\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003ctd\u003eMulti-Object Tracking\u003c/td\u003e\r\n      \u003ctd\u003eByteTrack\u003c/td\u003e\r\n      \u003ctd\u003e\u003cstrong\u003eUnstable.\u003c/strong\u003e ID switches are frequent due to visual similarity from top-down. Fixes expensive.\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\r\n---\r\n\r\n## Conclusion \u0026 Future Perspectives\r\n\r\nThe Basket-AI project successfully demonstrated that core components of a professional basketball tracking system can be replicated using modern computer vision and AI at a fraction of the cost. We built a robust pipeline for **player detection, ball localization, team assignment, and jersey number recognition.**\r\n\r\nThe primary hurdle, and the reason for the project's pause, was **Multi-Object Tracking (MOT)**. From this challenge, a broader insight emerged: the future of practical computer vision lies in solving robust, long-term MOT. Reliable MOT is the key that unlocks the transition from simple frame-by-frame detection to true **temporal understanding**:\r\n\r\n*   **In Sports:** Analyzing full plays, calculating player travel distance, and measuring team formation dynamics.  \r\n*   **In Autonomous Driving:** Tracking vehicles and pedestrians across time to predict trajectories.  \r\n*   **In Security \u0026 Retail:** Monitoring customer flow and behavior in a store over a complete session.  \r\n\r\nSolving MOT would democratize these advanced analytics, making them accessible without the need for the vast resources of large corporations or elite leagues. While Basket-AI is currently paused, it serves as a foundational proof-of-concept and a clear map toward the future of affordable, AI-powered sports analytics.\r\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-background\",\"children\":[[\"$\",\"$Ld\",null,{}],[\"$\",\"$Le\",null,{}],[\"$\",\"main\",null,{\"className\":\"max-w-6xl mx-auto my-10 px-1 sm:px-6 py-16 space-y-16\",\"children\":[[\"$\",\"$Lf\",null,{\"project\":{\"id\":\"basket-ai\",\"title\":\"Basket AI\",\"shortDescription\":\"Exploring computer vision techniques to generate live basketball box scores from video.\",\"image\":\"/images/projects/ai-basket.png\",\"github\":null,\"demo\":null,\"tags\":[\"Computer Vision\",\"YOLO\",\"ByteTrack\",\"K-Means\",\"SAM\",\"Parseq\"],\"markdown\":\"/markdown/basket-ai/basket-ai.md\",\"features\":[\"Player detection with YOLO\",\"Tracking using ByteTrack\",\"Squad clustering with K-Means\",\"Segmentation with SAM\",\"Number recognition with Parseq\"]}}],[\"$\",\"$L10\",null,{\"features\":\"$4:props:children:2:props:children:0:props:project:features\"}],[\"$\",\"$L11\",null,{\"markdown\":\"$12\"}]]}],[\"$\",\"$L13\",null,{}]]}]\n"])</script><script>self.__next_f.push([1,"9:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,"7:null\nb:[[\"$\",\"title\",\"0\",{\"children\":\"Lorenzo Signorelli\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"My porfolio website\"}]]\n"])</script></body></html>